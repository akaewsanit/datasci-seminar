{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forgot to add markdown describing what this will do"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install and import packages\n",
    "\n",
    "# %conda install pandas numpy emnist matplotlib\n",
    "\n",
    "# Import all the things\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import emnist\n",
    "from hashlib import sha1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data, and reshape it into a 28x28 array\n",
    "\n",
    "# The size of each image is 28x28\n",
    "size = 28 \n",
    "\n",
    "# Extract the training split as images and labels\n",
    "image, label = emnist.extract_training_samples('byclass')\n",
    "\n",
    "# Add columns for each pixel value (28x28 = 784 columns)\n",
    "raw_train = pd.DataFrame()\n",
    "\n",
    "\n",
    "\n",
    "# Add a column showing the label\n",
    "raw_train['label'] = label\n",
    "\n",
    "# Add a column with the image data as a 28x28 array\n",
    "raw_train['image'] = list(image)\n",
    "\n",
    "\n",
    "# Repeat for the test split\n",
    "image, label = emnist.extract_test_samples('byclass')\n",
    "raw_test = pd.DataFrame()\n",
    "raw_test['label'] = label\n",
    "raw_test['image'] = list(image)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can plot individual images using matplotlib\n",
    "plt.imshow(raw_train['image'][0], cmap='gray')\n",
    "plt.show() # Show the plot (optional with a single image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the first row for each label\n",
    "firsts = raw_train.groupby('label').first().reset_index()\n",
    "\n",
    "# Build a plot with the first image for each label\n",
    "fig, ax = plt.subplots(7, 10, figsize=(10, 7))\n",
    "for i in range(62):\n",
    "    ax[i//10, i%10].imshow(firsts['image'][i], cmap='gray')\n",
    "    ax[i//10, i%10].axis('off')\n",
    "    ax[i//10, i%10].set_title(firsts['label'][i])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To-do\n",
    "\n",
    "- [x] Add numerical var\n",
    "- [ ] Numerical: missing, outlier, out-of-bounds\n",
    "- [ ] Labels: missing(Null, None, \"\", \" \"), name that number, double-struck\n",
    "- [ ] Image: zeroed, null? dimensions?\n",
    "- [x] Image: add noise\n",
    "- [x] Image: flip horizonally\n",
    "- [x] Duplicated rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's mess up the data a bit\n",
    "\n",
    "# Percent of the time something dirty happens\n",
    "pct = 0.01 \n",
    "\n",
    "# Copy the splits into new dataframes to mess up\n",
    "dirty_train = raw_train.copy()\n",
    "dirty_test  = raw_test.copy()\n",
    "\n",
    "# Add a column for previous prediction score\n",
    "dirty_train['predict'] = np.random.rand(dirty_train.shape[0])\n",
    "dirty_test['predict']  = np.random.rand(dirty_test.shape[0])\n",
    "\n",
    "# Add a column for a hash of the images (should make it easier to compare them)\n",
    "dirty_train['image_hash'] = dirty_train['image'].apply(lambda x: sha1(x.tobytes()).hexdigest())\n",
    "dirty_test['image_hash']  =  dirty_test['image'].apply(lambda x: sha1(x.tobytes()).hexdigest())\n",
    "\n",
    "# TEMPLATE: For each row, XX% of the time, randomly apply method()\n",
    "# df['column'] = dirty_train['column'].apply(lambda x: method(x) if np.random.rand() < 0.XX else x)\n",
    "\n",
    "# For each row, 1% of the time, duplicate the row\n",
    "dirty_train = pd.concat([dirty_train, dirty_train.sample(frac=0.01)])\n",
    "dirty_test  = pd.concat([dirty_test,   dirty_test.sample(frac=0.01)])\n",
    "\n",
    "# For each row, 1% of the time, zero out the image array\n",
    "dirty_train['image'] = dirty_train['image'].apply(lambda x: np.zeros((size, size)) if np.random.rand() < 0.01 else x)\n",
    "dirty_test['image']  =  dirty_test['image'].apply(lambda x: np.zeros((size, size)) if np.random.rand() < 0.01 else x)\n",
    "\n",
    "# For each row, 1% of the time, add/subtract 1 to the predict column\n",
    "dirty_train['predict'] = dirty_train['predict'].apply(lambda x: x + 1 if np.random.rand() < 0.005 else x)\n",
    "dirty_test['predict']  =  dirty_test['predict'].apply(lambda x: x + 1 if np.random.rand() < 0.005 else x)\n",
    "dirty_train['predict'] = dirty_train['predict'].apply(lambda x: x - 1 if np.random.rand() < 0.005 else x)\n",
    "dirty_test['predict']  =  dirty_test['predict'].apply(lambda x: x - 1 if np.random.rand() < 0.005 else x)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# For each row, randomly decide whether to apply a random noise\n",
    "# dirty_train['image'] = dirty_train['image'].apply(lambda x: x + np.random.rand(size, size) if np.random.rand() < 0.1 else x)\n",
    "\n",
    "# For each row, randomly decide whether to flip the image horizontally\n",
    "#dirty_train['image'] = dirty_train['image'].apply(lambda x: np.flip(x, axis=1) if np.random.rand() < 0.1 else x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scratch cell\n",
    "# Capture an old copy of dirty test (run once manually)\n",
    "# dirty_last=dirty_test.copy()\n",
    "\n",
    "# last_hash = sha1(dirty_test.values.tobytes()).hexdigest()\n",
    "print(last_hash, sha1(dirty_test.values.tobytes()).hexdigest())\n",
    "\n",
    "# Check dupes\n",
    "# merged = dirty_last.merge(dirty_test, indicator=True, how='outer')\n",
    "# merged.loc = [merged['_merge'] != 'both']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the first image\n",
    "plt.imshow(dirty_train['image'][0], cmap='gray')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning\n",
    "\n",
    "The changes above were applied randomly, so we'll need to find them and make a plan to fix them.\n",
    "\n",
    "- [ ] Create a column to identify whether each row came from *train* or *test*\n",
    "- [ ] (optional) Merge the data into a single\n",
    "- [ ] Explore the data to understand what's in it\n",
    "- [ ] List potential data issues to fix\n",
    "- [ ] Create a friendlier column for image labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's start cleaning!\n",
    "\n",
    "# Just going to leave this here in case anyone finds it helpful\n",
    "LABELS = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', \n",
    "          'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z',\n",
    "          'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
    "\n",
    "# Add a column showing which split (train vs test) each row came from\n",
    "raw_train['split'] = 'train'\n",
    "raw_test['split'] = 'test'\n",
    "\n",
    "# Add a column for a hash of the images (should make it easier to compare them)\n",
    "dirty_train['image_hash'] = dirty_train['image'].apply(lambda x: sha1(x.tobytes()).hexdigest())\n",
    "dirty_test['image_hash']  =  dirty_test['image'].apply(lambda x: sha1(x.tobytes()).hexdigest())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "seminar",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5e515f099f0da6a2737b6685058153dc4c80cb25a1e9fe8c5e831073d214043c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
